Search.setIndex({"alltitles": {"Data analysis": [[4, "data-analysis"]], "Exercise I": [[4, "exercise-i"]], "Exercise II": [[4, "exercise-ii"]], "Exercise: Minari data collection": [[3, null]], "Exercise: Offline RL algorithms": [[4, null]], "Final remarks": [[4, "final-remarks"]], "Important Note": [[1, "important-note"]], "Introduction to Offline Reinforcement Learning": [[1, null]], "MINARI Dataset": [[2, "minari-dataset"]], "Minari dataset structure": [[2, "minari-dataset-structure"]], "Offline RL Notes": [[0, null]], "Offline RL vs supervised learning": [[1, "offline-rl-vs-supervised-learning"]], "Offline RL/IL pipeline": [[1, "offline-rl-il-pipeline"]], "Online vs offline learning comparison.": [[1, "online-vs-offline-learning-comparison"]], "Open Source Datasets libraries for offline RL": [[2, null]], "Open X-Embodiment Repository": [[2, "open-x-embodiment-repository"]], "Problem Overview: Offline vs. Online RL": [[1, "problem-overview-offline-vs-online-rl"]], "RL Unplugged dataset": [[2, "rl-unplugged-dataset"]], "References": [[1, "references"], [2, "references"], [3, "references"]], "STEP 1: Create the environment": [[4, "step-1-create-the-environment"], [4, "id1"]], "STEP 1: Create the environments": [[3, "step-1-create-the-environments"]], "STEP 2: Create Minari datasets": [[3, "step-2-create-minari-datasets"], [4, "step-2-create-minari-datasets"], [4, "id2"]], "STEP 3: Feed data into replay buffer": [[4, "step-3-feed-data-into-replay-buffer"], [4, "id3"]], "STEP 3: Feed dataset to Tianshou ReplayBuffer": [[3, "step-3-feed-dataset-to-tianshou-replaybuffer"]], "STEP 4-5: Select offline policies and training": [[4, "step-4-5-select-offline-policies-and-training"]], "STEP 4: Select offline policies and training": [[4, "step-4-select-offline-policies-and-training"]], "Summary and conclusions": [[4, "summary-and-conclusions"]], "Useful minari methods": [[2, "useful-minari-methods"]]}, "docnames": ["intro", "nb_0_IntroOfflineRL", "nb_1_offline_RL_dataset_libraries", "nb_2_data_dollection", "nb_4_Offline_rl_exercises"], "envversion": {"sphinx": 62, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1}, "filenames": ["intro.md", "nb_0_IntroOfflineRL.ipynb", "nb_1_offline_RL_dataset_libraries.ipynb", "nb_2_data_dollection.ipynb", "nb_4_Offline_rl_exercises.ipynb"], "indexentries": {}, "objects": {}, "objnames": {}, "objtypes": {}, "terms": {"": [1, 2, 3, 4], "0": [1, 2, 3, 4], "1": [1, 2], "10": 3, "100": [3, 4], "1000": 4, "12": [1, 2, 3, 4], "128": 4, "2": [1, 2], "2000": 4, "2021": [1, 2], "2023": [1, 2], "22": 2, "2d": [1, 3], "3": [1, 2], "33": 2, "4": [1, 2], "5": [1, 2], "500": 3, "6": [2, 4], "600": 4, "64": 3, "7": 4, "8x8": 3, "A": [1, 2, 3], "And": 2, "As": [1, 2], "Be": 1, "But": 1, "For": [1, 2], "If": [0, 1], "In": [1, 2, 3, 4], "It": [1, 2, 3, 4], "Its": 2, "On": [1, 2], "One": [1, 4], "The": [1, 2, 3, 4], "There": 1, "These": [0, 1, 2], "To": 3, "With": 1, "_": [1, 3, 4], "_collected_data_nb_92": 3, "_expert": 4, "_longer_path": 4, "_short_path": 4, "_stiching_property_i": 4, "_suboptim": 4, "a_0": 1, "a_1": 1, "a_t": 1, "abl": [1, 2, 4], "about": [1, 4], "abov": 1, "abund": 4, "academ": 2, "acceler": 1, "accept": 1, "access": [1, 2, 3, 4], "accur": [1, 2, 4], "achiev": [2, 4], "across": [1, 4], "action": [1, 3, 4], "action_i": 2, "activ": 1, "ad": 1, "adapt": 1, "addition": 1, "address": [1, 4], "adopt": 1, "adroithandhamm": 3, "advanc": 2, "advantag": 1, "after": 1, "again": 4, "agent": [1, 2, 3, 4], "aid": 4, "aim": [1, 2], "al": [1, 2, 3], "algorithm": [1, 2], "all": [0, 1], "allow": [1, 2], "almost": 1, "along": 1, "alreadi": [1, 4], "also": [1, 2, 3], "although": 2, "alwai": 1, "amount": [1, 4], "ampl": 4, "an": [1, 2, 3, 4], "analyz": [1, 3], "ani": [1, 2, 3], "anoth": 4, "anywai": 1, "apart": 1, "api": [2, 3], "appear": 2, "appli": [1, 4], "applic": [1, 4], "approach": [1, 2, 4], "ar": [1, 2, 3, 4], "area": [1, 2], "argmin_": 1, "aris": 2, "around": [0, 1, 3], "assess": 4, "assum": 1, "attach": 1, "attempt": 1, "attent": 2, "attract": 2, "automot": 2, "autonom": [1, 2, 4], "autoreload": [1, 2, 3, 4], "avail": 4, "available_obstacl": 4, "avoid": 1, "b": 4, "back": 1, "base": [1, 2], "batch": 1, "batch_siz": 4, "bc": [1, 4], "bcq": 4, "bcq_discret": 4, "becaus": [1, 2, 4], "becom": [2, 4], "befor": [1, 2, 4], "beforehand": 1, "behavior": [1, 2, 3, 4], "behavior_8x8_eps_greedy_4_0_to_7_7": 4, "behavior_polici": [3, 4], "behavior_policy_grid_world": 3, "behavior_policy_i": 4, "behavior_policy_ii": 4, "behavior_policy_nam": 4, "behavior_policy_registri": [3, 4], "behaviorpolicy2dgridfactori": [3, 4], "behaviorpolicytyp": 4, "being": 1, "belong": 1, "below": 1, "benchmark": 2, "benefici": 1, "berkelei": 2, "best": [1, 2], "beta": 1, "better": 2, "between": [1, 4], "beyond": 1, "bias": 2, "big": 1, "blog": 2, "both": 4, "brain": 2, "break": 3, "buffer_data": [3, 4], "build": 1, "c": [1, 2, 4], "call": [1, 2], "camera": 2, "can": [1, 2, 3, 4], "cannot": [1, 4], "capabl": [1, 4], "captur": [1, 2, 3, 4], "car": [1, 2], "care": 1, "carri": 1, "carrot": 1, "case": [1, 4], "centric": 4, "challeng": [1, 2, 4], "chang": 4, "cheaper": 1, "check": 4, "children_dataset_nam": 4, "choic": [2, 4], "chosen": 4, "class": 2, "classic": 2, "clear": 2, "clearer": 1, "clone": 1, "close": [1, 2, 4], "code": [1, 3], "collect": [1, 2, 4], "collis": 1, "color": 1, "combin": [1, 2], "combine_dataset": 2, "combined_data_sets_offline_rl": 4, "combined_dataset": 4, "combined_dataset_identifi": 4, "come": [1, 2, 4], "common": 2, "commun": [1, 2], "compar": [1, 4], "complex": [1, 2, 4], "complic": 1, "compress": 2, "comput": [1, 3, 4], "concept": 1, "concern": 1, "config_combined_data": 4, "configur": 4, "congratul": 3, "connect": 4, "consequ": 4, "consid": 1, "constraint": 1, "consum": 1, "consumpt": 1, "contact": 1, "contain": [0, 1, 2], "continu": 1, "contrast": 1, "control": [1, 2], "convert": 2, "coordin": 3, "core": 1, "cost": 1, "costli": [1, 2], "could": [1, 2], "cover": 4, "cpu": 4, "cql": 4, "cql_discret": 4, "craft": [2, 4], "creat": 1, "create_combined_minari_dataset": 4, "create_dataset": 2, "create_dataset_from_buff": 2, "create_minari_dataset": 3, "criteria": 2, "critic": [1, 4], "crucial": [1, 2, 4], "cucumb": 1, "current": 1, "custom": [1, 2], "custom2dgridenv": 3, "custom_2d_grid_env": [3, 4], "custom_env": [3, 4], "custom_envs_registr": [3, 4], "customenv": 4, "cycl": 1, "d": [1, 4], "d4rl": [2, 3], "d_": 1, "danger": 1, "data": [1, 2], "data_s": 4, "data_set_config": 3, "data_set_identifier_i": [3, 4], "data_set_identifier_ii": 4, "data_set_nam": [3, 4], "datacollector": 2, "dataset": 1, "dataset_avail": 4, "dataset_identifi": [3, 4], "deal": [1, 4], "decis": 1, "deep": [2, 3], "defin": [1, 2], "definit": 1, "demand": 4, "demonstr": [1, 2], "denot": 1, "deriv": 1, "describ": 0, "descript": 3, "design": [1, 2], "destroi": 4, "detect": 1, "determin": 1, "determinist": 2, "deterministic_8x8": [3, 4], "develop": 1, "devic": 4, "diagnosi": 1, "did": [1, 2, 4], "didn": 2, "differ": [1, 2, 3], "difficult": [1, 2], "dimens": 3, "dimension": [1, 3], "direct": 3, "directli": 1, "directori": 2, "discount": 1, "discov": 1, "discrep": 1, "discuss": 2, "displai": 3, "distinct": 1, "distribut": [1, 2, 3, 4], "divers": [2, 4], "dnn": 1, "do": [1, 4], "docker": 0, "document": [2, 3], "doesn": 1, "domain": [1, 2], "don": [1, 3], "done": 4, "down": 3, "drift": 4, "drive": [1, 2, 4], "driven": [1, 2, 3], "due": [1, 4], "dure": 1, "dynam": 4, "e": [1, 2, 4], "each": 3, "easi": 2, "easier": [1, 2], "edg": 4, "edit": 0, "effect": [1, 2, 4], "effici": [1, 2, 4], "egl": 3, "elem": 3, "elif": 4, "els": [3, 4], "embodi": 4, "encod": 3, "encount": 1, "end": 2, "energi": 1, "enhanc": 4, "entir": 1, "env": [3, 4], "env_2d_grid_initial_config": 4, "env_2d_grid_initial_config_i": 4, "env_2d_grid_initial_config_ii": 4, "env_list": 3, "env_nam": [3, 4], "env_or_env_nam": [3, 4], "env_wrapp": 4, "envfactori": [3, 4], "environ": [1, 2], "environment": 1, "episod": 1, "epsilon": 1, "equal": 2, "equat": 4, "error": [1, 4], "especi": [1, 2, 4], "essenti": 1, "estim": 1, "et": [1, 2, 3], "evalu": [1, 2, 4], "even": 1, "everyth": 2, "everywher": 2, "evid": 4, "evolv": 4, "examin": 4, "exampl": [1, 3], "except": 2, "exclud": 1, "execut": 0, "exemplifi": 4, "exercis": 1, "exist": [1, 2], "expect": 1, "expens": 1, "experi": 1, "expert": [1, 2, 4], "explain": 2, "explan": 1, "explor": [1, 2, 3, 4], "extens": 4, "extract": 2, "f": 3, "facilit": 1, "fair": 1, "fals": 4, "familiar": [2, 3], "far": 1, "fast": 1, "faster": 1, "feasibl": 1, "feed": 1, "feedback": [1, 4], "feel": 0, "field": 1, "fig": 1, "figur": [1, 2], "file": 2, "filterwarn": [3, 4], "final_st": 4, "final_state_polici": 4, "financ": 1, "financi": 1, "find": [1, 2, 4], "first": [3, 4], "fix": [1, 2], "focu": 2, "focus": [1, 4], "folder": [1, 2], "follow": [1, 2, 3], "forecast": 4, "form": 1, "format": [1, 2], "forward": 1, "four": 4, "fp": 3, "free": 0, "from": [1, 2, 3, 4], "fu": [2, 3], "fulli": 1, "function": [1, 2], "further": 1, "furthermor": 4, "g": 2, "gain": [2, 4], "gamma": 1, "gather": [1, 2], "gcp": 2, "gener": [1, 2], "generate_custom_minari_dataset": [3, 4], "generate_minari_dataset": [3, 4], "get": [1, 2, 3, 4], "get_env": [3, 4], "get_state_action_data_and_policy_grid_distribut": [3, 4], "get_trained_policy_path": 4, "github": 2, "give": [1, 2, 3], "given": 1, "go": [1, 2, 4], "goal": [1, 2, 4], "goe": [1, 4], "good": [1, 3], "googl": 2, "grasp": 4, "green": [1, 2], "grid": [1, 3, 4], "grid2dinitialconfig": 4, "grid_2d_8x8_discret": [3, 4], "grid_config": 4, "grid_world_obstacl": 3, "groot": 2, "group": 2, "gulcehr": 2, "gym": [3, 4], "gymnasium": [2, 3, 4], "h": [1, 2], "h5py": 2, "ha": 2, "halfcheetah": 3, "hand": [1, 2, 4], "handl": 2, "hard": 1, "have": [1, 2, 3, 4], "hdf5": 2, "health": 1, "healthcar": [1, 4], "help": [1, 2], "here": 2, "hesit": 1, "higer": 4, "high": 1, "higher": 4, "highest": 1, "highli": 1, "histor": [1, 2], "home": 3, "homework": 3, "horizon": 1, "horizont": 3, "host": 3, "hot": 3, "how": [1, 2, 4], "howev": [1, 4], "human": [1, 2], "humanoid": [2, 3], "hyperparamet": 4, "i": [1, 2, 3], "id": 3, "idea": [1, 3], "ideal": 1, "identifi": 2, "identifier_combined_dataset": 4, "ignor": [3, 4], "illustr": 1, "imit": [1, 2, 4], "imitation_learn": 4, "imitation_policy_sampl": 4, "impact": 1, "import": [3, 4], "importantli": 4, "impos": 1, "imposs": [1, 4], "improv": [1, 2], "inaccur": 4, "includ": [2, 4], "increas": 1, "indic": 3, "industri": 1, "info_i": 2, "inform": 3, "infti": 1, "initial_st": 4, "initial_state_policy_i": 4, "initial_state_policy_ii": 4, "inlin": [1, 2, 3, 4], "instal": 0, "instanc": 2, "instead": 1, "integ": 3, "intellig": 4, "intend": 2, "interact": [1, 2], "internet": 2, "intervent": 1, "intric": 1, "introduc": [1, 2], "intuit": 1, "invertedpendulum": 3, "invest": 1, "involv": [1, 2, 4], "ipynb": 1, "isinst": 3, "isn": 1, "issu": [1, 2, 4], "its": 4, "j": 1, "jovyan": 3, "jupyt": 0, "just": [1, 2], "justin": [2, 3], "kei": [1, 2], "knowledg": 1, "l_": 1, "lab": 2, "lack": 1, "landscap": 4, "larg": [1, 2, 4], "larger": 4, "later": [1, 2], "ldot": 1, "le": 1, "lead": [1, 2], "learn": [2, 3, 4], "left": [1, 3, 4], "len": [3, 4], "len_buff": 4, "let": [1, 2, 3, 4], "level": 1, "leverag": 4, "levin": 1, "li": 1, "librari": 1, "lidar": 1, "like": [1, 2, 4], "limit": 1, "line": 1, "link": 2, "list": [2, 3], "list_local_dataset": 2, "littl": [1, 4], "ll": [1, 2, 4], "load": [2, 4], "load_buffer_minari": [3, 4], "load_dataset": 2, "load_env_vari": [3, 4], "load_ext": [1, 2, 3, 4], "load_latex_macro": [2, 3], "load_state_dict": 4, "localhost": 3, "log_nam": 4, "log_path": 4, "logdir": 3, "look": [0, 2, 3], "lot": 2, "machin": 2, "made": 2, "mai": [1, 2], "main": [1, 2], "mainli": 2, "major": [1, 2, 4], "make": [1, 2, 3, 4], "manag": 1, "mani": [1, 2, 4], "manipul": [1, 2], "manner": 1, "manual": 1, "manufactur": 2, "map_loc": 4, "market": 1, "markov": 1, "markovian": 2, "match": 2, "mathbb": 1, "matplotlib": [1, 2, 3, 4], "md": 0, "mean": 2, "meat": 1, "medium": 2, "memori": 2, "mention": 1, "merg": 2, "meta": 2, "metadata": [2, 4], "method": [1, 4], "might": [1, 2], "minari": 1, "mind": 2, "minim": 1, "mirror": 1, "miss": 1, "mitig": 1, "mix": 3, "mixtur": 1, "model": [1, 2, 4], "more": [1, 4], "most": 2, "mostli": 1, "move": [1, 4], "move_left": 4, "move_right": 4, "move_up": 4, "mujoco": 2, "mujoco_gl": 3, "multi": 2, "multipl": 2, "multitask": [2, 4], "must": 1, "my": 0, "n": 1, "name_expert_data": 4, "narrow": 2, "navig": [1, 4], "nb_3_offline_rl_theori": 1, "ne": 1, "necessarili": 1, "need": [1, 2, 3], "nevertheless": 4, "new": [1, 2, 4], "nois": [2, 4], "non": 2, "normal": 4, "notat": 1, "note": 4, "notebook": [0, 1, 3], "notic": 4, "now": [1, 2, 3, 4], "np": 4, "num_collected_point": [3, 4], "num_epoch": 4, "num_fram": [3, 4], "num_steps_i": [3, 4], "num_steps_ii": 4, "number": [1, 3], "number_test_env": 4, "numpi": 4, "nvidia": 2, "o": [1, 3, 4], "object": 2, "observ": [1, 2, 3], "obst": 3, "obst_free_8x8": [3, 4], "obstacl": [1, 3, 4], "obstacle_8x8_top_right": 3, "obstacle_8x8_wall_with_door": 4, "obstacle_select": 4, "obstacles_2d_grid_regist": [3, 4], "obstacletyp": [3, 4], "occur": 1, "octob": 2, "off": [1, 4], "offer": 2, "offilin": 4, "offlin": 3, "offline_polici": [3, 4], "offline_policy_config": 4, "offline_rl": [1, 3, 4], "offline_rl_polici": 4, "offline_train": 4, "offline_training_hyperparam": 4, "offlinerltrain": 4, "offlinetraininghyperparam": 4, "offpolicy_rend": [3, 4], "often": [1, 2], "onc": [1, 4], "one": [1, 2, 3, 4], "ones": 4, "onion": 1, "onli": [1, 2, 4], "onlin": [2, 4], "open": [1, 4], "oper": 1, "opportun": 4, "optim": [1, 2, 4], "option": [1, 4], "order": [1, 4], "organ": 2, "origin": 1, "other": [1, 2, 4], "otherwis": 1, "our": [1, 2, 3, 4], "out": [1, 2, 4], "outperform": [1, 4], "outsid": 1, "over": 1, "overestim": 1, "overli": 2, "own": 1, "padalkar": 2, "page": 0, "pair": 4, "paramount": 4, "partial": [1, 2], "particular": 2, "particularli": 1, "partner": 2, "past": 1, "path": [2, 4], "pathlib": 4, "patienc": 1, "patient": 1, "peak": 4, "percept": 4, "perfect": 2, "perform": [1, 2], "person": 0, "perspect": 1, "pi": 1, "pi_": 1, "pi_b": [1, 2], "pictur": 1, "pipelin": [3, 4], "plai": [1, 3, 4], "pleas": 1, "plt": 4, "point": [1, 2, 3, 4], "polici": [1, 2, 3], "policy_best_reward": 4, "policy_config_data_class": 4, "policy_model": 4, "policy_registri": 4, "policy_select": 4, "portfolio": 1, "portion": 4, "pose": 2, "posit": 3, "possibl": [1, 4], "potenti": 4, "power": 4, "practic": 1, "pre": 2, "predict": 1, "prefer": 1, "prepar": 1, "preprocess": 2, "present": 1, "presentation_styl": [2, 3], "previou": [1, 2, 4], "previous": [1, 2], "primari": 1, "primarili": 1, "print": 3, "probabl": 4, "process": [1, 2, 4], "produc": [1, 4], "program": 4, "project": 2, "promin": 4, "propag": [1, 4], "propel": 2, "properti": [2, 4], "prove": 4, "provid": [1, 2, 4], "prudencio": 1, "pth": 4, "purpos": 2, "pyplot": 4, "quad": 1, "qualiti": 1, "question": [1, 4], "quick": 1, "quickli": 1, "quit": 1, "r": 1, "rais": 3, "random": [1, 2, 3], "rang": 3, "rare": 4, "rather": 2, "reach": 4, "readm": 0, "real": [1, 2, 4], "realist": [2, 4], "reason": [1, 4], "recov": [1, 4], "red": 1, "reduc": 1, "refer": 0, "refin": 1, "region": [1, 4], "regist": [2, 3], "reinforc": [2, 3, 4], "relat": 1, "rememb": 3, "render": [0, 3], "render_mod": [3, 4], "rendermod": [3, 4], "replac": 2, "repres": [1, 2, 3], "represent": 2, "requir": [0, 1, 2, 4], "restor": 4, "restore_polici": 4, "restore_train": 4, "result": [1, 2, 4], "return": [1, 4], "reus": 1, "review": 1, "reward": [1, 2, 4], "reward_i": 2, "rgb_arrai": 4, "rgb_array_list": 3, "right": [1, 3], "riski": 1, "rl": 3, "rl_policy_model": 4, "rlpolicyfactori": 4, "robot": [1, 2, 4], "robust": 4, "rollout": 2, "room": 1, "rt": 2, "rule": 1, "s_0": 1, "s_1": 1, "s_t": 1, "safe": 1, "safer": 1, "safeti": 4, "sampl": 1, "save": 2, "saved_policy_nam": 4, "scale": [1, 2], "scenario": [2, 4], "scope": 2, "search": 2, "second": 4, "section": 2, "see": [1, 4], "seen": [1, 2], "select": [1, 3], "select_policy_to_rend": 4, "selected_data_set": 4, "selected_environ": 3, "selected_grid_world_polici": 3, "selected_obstacl": [3, 4], "selected_offline_rl_polici": 4, "self": 1, "sensor": [1, 2], "seriou": 4, "serv": 0, "set": 1, "set_goal_point": 4, "set_new_obstacle_map": [3, 4], "set_random_se": [1, 2, 3, 4], "set_starting_point": 4, "setup": [2, 4], "sever": 1, "shift": 1, "short": 2, "should": [1, 2, 3], "shown": 1, "signific": [2, 4], "sim": 1, "simeq": 1, "similar": [2, 4], "simple_grid": 3, "simpler": 1, "simplest": 1, "simplifi": 1, "simul": [1, 2, 4], "sinc": [1, 2], "situat": [1, 2], "size": [1, 2], "skill": 1, "slice": 2, "slide": 1, "small": 4, "smaller": 2, "snapshot_env": [3, 4], "so": [1, 2, 4], "sole": [1, 4], "solut": 1, "solv": [1, 2], "some": [1, 4], "sometim": 1, "somewhat": 2, "soon": 1, "soup": 1, "sourc": 3, "space": 1, "spars": 2, "spec": 3, "specif": [1, 2, 4], "split": 2, "src": [1, 3], "standard": [1, 2], "start": [0, 4], "start_0_0": 4, "start_2_0": 4, "state": [1, 2, 3, 4], "state_action_count_data": [3, 4], "state_i": 2, "static": 1, "step": 1, "step_per_epoch": 4, "still": 2, "stitch": [2, 4], "stop": [1, 4], "storag": 2, "store": 2, "str": 4, "straightforward": 1, "strategi": [1, 4], "strict": 1, "structur": 3, "studi": [2, 4], "suboptim": [1, 2, 4], "suboptimal_8x8": 3, "subset": [1, 2], "substanti": 1, "success": 2, "suffici": 1, "suggest": 2, "suit": 2, "suitabl": 2, "sum_": 1, "sum_t": 1, "summari": 1, "superior": 1, "supervis": 2, "support": 2, "suppos": 2, "survei": 1, "symptom": 1, "t": [1, 2, 3], "tackl": 1, "tag": 1, "tailor": 2, "take": [3, 4], "target": 4, "target_st": 4, "task": [1, 2, 4], "tau": 1, "tau_i": 1, "taxonomi": 1, "teach": 2, "techniqu": 1, "tend": [1, 4], "tendenc": 4, "tensorboard": 3, "term": 1, "termin": 1, "termination_i": 2, "test": [1, 2], "text": 1, "tfl": 3, "than": [1, 2], "thei": [2, 4], "them": [1, 2, 4], "theta": 1, "thi": [1, 2, 3, 4], "think": [1, 4], "those": [1, 4], "through": 2, "ti": 2, "tianshou": 1, "time": [1, 3, 4], "torch": 4, "total": 1, "toward": 4, "trade": 1, "train": [1, 2, 3], "trainedpolicyconfig": 4, "training_interfac": 4, "training_rl": 3, "trajectori": [1, 2, 4], "transfer": [2, 4], "transit": 1, "treat": 1, "treatment": 1, "true": [1, 4], "truli": 1, "truncation_i": 2, "try": 1, "turn": 4, "tutori": 1, "two": [1, 2, 4], "type": [1, 2, 3], "typic": [1, 2], "u": [1, 2], "uc": 2, "undirect": 2, "unknown": 1, "unless": 4, "unlik": 1, "unpredict": 4, "unrel": 1, "unwrap": 3, "up": 3, "us": [0, 1, 3, 4], "usag": 1, "user": 2, "usual": 1, "util": [1, 2, 3, 4], "v1": 3, "v4": 3, "valid": 1, "valu": [3, 4], "valuabl": [2, 4], "valueerror": 3, "vari": 1, "varianc": 1, "variou": [1, 2, 4], "vast": [2, 4], "vector": 3, "vehicl": 1, "veri": [1, 4], "vertic": 3, "viabl": [1, 4], "video": 2, "visual": [3, 4], "wa": 2, "wai": [2, 3], "want": [0, 1, 4], "warn": [3, 4], "we": [1, 2, 3, 4], "welcom": 0, "well": [2, 4], "were": 1, "what": [1, 2, 4], "when": [1, 4], "where": [1, 2, 4], "wherea": 1, "whether": [1, 2], "which": [1, 2, 4], "while": [1, 2], "who": 1, "why": [1, 4], "wide": 1, "widespread": 1, "widget_list": [3, 4], "window": 2, "within": [1, 2], "without": [1, 2, 4], "work": [1, 2], "world": [1, 2, 3, 4], "worri": 1, "would": [1, 3, 4], "wrapper": 2, "wrong": 1, "x": 4, "x_1": 3, "x_2": 3, "ye": 1, "yellow": 2, "you": [0, 1, 3, 4], "your": [1, 2, 3, 4]}, "titles": ["Offline RL Notes", "Introduction to Offline Reinforcement Learning", "Open Source Datasets libraries for offline RL", "Exercise: Minari data collection", "Exercise: Offline RL algorithms"], "titleterms": {"1": [3, 4], "2": [3, 4], "3": [3, 4], "4": 4, "5": 4, "algorithm": 4, "analysi": 4, "buffer": 4, "collect": 3, "comparison": 1, "conclus": 4, "creat": [3, 4], "data": [3, 4], "dataset": [2, 3, 4], "embodi": 2, "environ": [3, 4], "exercis": [3, 4], "feed": [3, 4], "final": 4, "i": 4, "ii": 4, "il": 1, "import": 1, "introduct": 1, "learn": 1, "librari": 2, "method": 2, "minari": [2, 3, 4], "note": [0, 1], "offlin": [0, 1, 2, 4], "onlin": 1, "open": 2, "overview": 1, "pipelin": 1, "polici": 4, "problem": 1, "refer": [1, 2, 3], "reinforc": 1, "remark": 4, "replai": 4, "replaybuff": 3, "repositori": 2, "rl": [0, 1, 2, 4], "select": 4, "sourc": 2, "step": [3, 4], "structur": 2, "summari": 4, "supervis": 1, "tianshou": 3, "train": 4, "unplug": 2, "us": 2, "v": 1, "x": 2}})